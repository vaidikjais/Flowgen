# Flowgen üé®

A production-ready FastAPI application that generates beautiful diagrams from natural language descriptions using LLM and Graphviz.

## üåü Features

- **Natural Language to Diagrams**: Describe what you want in plain English, get a professional diagram
- **Multiple Output Formats**: SVG (vector) and PNG (raster) support
- **Multiple Layout Engines**: Choose from dot, neato, fdp, sfdp, twopi, and circo
- **REST API**: Clean, well-documented endpoints
- **Modern Web UI**: Beautiful, responsive frontend included
- **Docker Ready**: Production-ready containerization
- **Type Safe**: Full type hints and Pydantic validation
- **Error Handling**: Comprehensive error handling and validation

## üìã Prerequisites

### System Requirements

1. **Python 3.11+**
2. **Graphviz** (system binaries required)

### Install Graphviz

#### macOS
```bash
brew install graphviz
```

#### Ubuntu/Debian
```bash
sudo apt-get update
sudo apt-get install graphviz libgraphviz-dev
```

#### Windows
Download and install from [Graphviz Downloads](https://graphviz.org/download/)

After installation, ensure `dot` is in your PATH:
```bash
dot -V  # Should print Graphviz version
```

### LLM API Keys

Choose your preferred LLM provider:

**Option 1: OpenAI**
- Get your API key from [OpenAI Platform](https://platform.openai.com/api-keys)

**Option 2: NVIDIA NIM**
- Get your API key from [NVIDIA NIM](https://build.nvidia.com/explore/discover)
- Supports models like `qwen3-next-80b-a3b-instruct`, `meta/llama-3.1-405b-instruct`, etc.

## üöÄ Quick Start

### 1. Clone and Setup

```bash
# Clone repository
cd Flowgen

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure Environment

Create a `.env` file or export environment variables:

**For OpenAI:**
```bash
# LLM Provider
export LLM_PROVIDER="openai"

# OpenAI Configuration (Required)
export OPENAI_API_KEY="sk-your-api-key-here"
export OPENAI_MODEL="gpt-4"                    # or gpt-3.5-turbo

# Optional (with defaults)
export HOST="0.0.0.0"
export PORT="8000"
export MAX_PROMPT_LENGTH="2000"
export MAX_DOT_LENGTH="50000"
export MAX_TOKENS="1024"
export LOG_LEVEL="INFO"
```

**For NVIDIA NIM:**
```bash
# LLM Provider
export LLM_PROVIDER="nvidia"

# NVIDIA NIM Configuration (Required)
export NVIDIA_API_KEY="nvapi-your-key-here"
export NVIDIA_MODEL="qwen3-next-80b-a3b-instruct"

# Optional (with defaults)
export NVIDIA_BASE_URL="https://integrate.api.nvidia.com/v1"
export HOST="0.0.0.0"
export PORT="8000"
export MAX_PROMPT_LENGTH="2000"
export MAX_DOT_LENGTH="50000"
export MAX_TOKENS="1024"
export LOG_LEVEL="INFO"
```

### 3. Run the Application

```bash
# Development mode
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Production mode
python -m app.main
```

Visit [http://localhost:8000](http://localhost:8000) to use the web interface!

## üê≥ Docker Deployment

### Build and Run

```bash
# Build image
docker build -t flowgen .

# Run container with OpenAI
docker run -d \
  -p 8000:8000 \
  -e LLM_PROVIDER="openai" \
  -e OPENAI_API_KEY="sk-your-api-key-here" \
  -e OPENAI_MODEL="gpt-4" \
  --name flowgen \
  flowgen

# Or run with NVIDIA NIM
docker run -d \
  -p 8000:8000 \
  -e LLM_PROVIDER="nvidia" \
  -e NVIDIA_API_KEY="nvapi-your-key-here" \
  -e NVIDIA_MODEL="qwen3-next-80b-a3b-instruct" \
  --name flowgen \
  flowgen
```

### Using Docker Compose

Create `docker-compose.yml`:

```yaml
version: '3.8'

services:
  flowgen:
    build: .
    ports:
      - "8000:8000"
    environment:
      # Choose your provider
      - LLM_PROVIDER=nvidia  # or "openai"
      
      # OpenAI Configuration (if using OpenAI)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=gpt-4
      
      # NVIDIA NIM Configuration (if using NVIDIA)
      - NVIDIA_API_KEY=${NVIDIA_API_KEY}
      - NVIDIA_MODEL=qwen3-next-80b-a3b-instruct
      
      - LOG_LEVEL=INFO
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/api/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
```

Run with:
```bash
docker-compose up -d
```

## üìö API Documentation

### Endpoints

#### 1. Generate Diagram from Prompt

**POST** `/api/diagram/generate`

Generate a diagram from natural language description.

**Request Body:**
```json
{
  "prompt": "Draw a flowchart for user signup with validation and error handling",
  "format": "svg",
  "layout": "dot"
}
```

**Parameters:**
- `prompt` (string, required): Natural language description of the diagram
- `format` (string, optional): Output format - "svg" or "png" (default: "svg")
- `layout` (string, optional): Graphviz engine - "dot", "neato", "fdp", "sfdp", "twopi", "circo" (default: "dot")

**Response:**
- Default: Image with appropriate `Content-Type` (image/svg+xml or image/png)
- With `Accept: application/json` header:
```json
{
  "diagram_dot": "digraph {...}",
  "image_base64": "PD94bWwgdmVyc2lvbj0...",
  "format": "svg"
}
```

**Example cURL:**
```bash
# Get SVG directly
curl -X POST http://localhost:8000/api/diagram/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Draw a flowchart for user login with username/password validation",
    "format": "svg"
  }' \
  --output diagram.svg

# Get PNG
curl -X POST http://localhost:8000/api/diagram/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Create a network diagram with router, firewall, and servers",
    "format": "png"
  }' \
  --output diagram.png

# Get JSON response
curl -X POST http://localhost:8000/api/diagram/generate \
  -H "Content-Type: application/json" \
  -H "Accept: application/json" \
  -d '{
    "prompt": "Show a class diagram for e-commerce system",
    "format": "svg"
  }'
```

#### 2. Preview Diagram from DOT Code

**POST** `/api/diagram/preview`

Render a diagram from Graphviz DOT code directly (no LLM call).

**Request Body:**
```json
{
  "dot": "digraph { A -> B; B -> C; }",
  "format": "svg",
  "layout": "dot"
}
```

**Example cURL:**
```bash
curl -X POST http://localhost:8000/api/diagram/preview \
  -H "Content-Type: application/json" \
  -d '{
    "dot": "digraph test { rankdir=LR; A -> B -> C; }",
    "format": "svg"
  }' \
  --output preview.svg
```

#### 3. Health Check

**GET** `/api/health`

Check if the service is running.

**Response:**
```json
{
  "status": "ok",
  "version": "1.0.0"
}
```

**Example cURL:**
```bash
curl http://localhost:8000/api/health
```

### Interactive API Documentation

Once the server is running, visit:
- **Swagger UI**: [http://localhost:8000/docs](http://localhost:8000/docs)
- **ReDoc**: [http://localhost:8000/redoc](http://localhost:8000/redoc)

## üß™ Testing

```bash
# Install test dependencies (included in requirements.txt)
pip install pytest pytest-asyncio httpx

# Run tests
pytest tests/ -v

# Run with coverage
pytest tests/ -v --cov=app --cov-report=html

# Run specific test file
pytest tests/test_render.py -v
```

## üèóÔ∏è Project Structure

```
flowgen/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # FastAPI application and endpoints
‚îÇ   ‚îú‚îÄ‚îÄ llm_client.py        # OpenAI LLM wrapper
‚îÇ   ‚îú‚îÄ‚îÄ diagram_renderer.py  # Graphviz rendering functions
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py           # Pydantic models
‚îÇ   ‚îî‚îÄ‚îÄ config.py            # Configuration management
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îî‚îÄ‚îÄ index.html           # Web UI
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ test_render.py       # Unit tests
‚îú‚îÄ‚îÄ Dockerfile               # Docker configuration
‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies
‚îî‚îÄ‚îÄ README.md               # This file
```

## üîí Production Considerations

### Security

1. **API Key Management**: Never commit API keys. Use environment variables or secrets management.
2. **Rate Limiting**: Implement rate limiting (e.g., using slowapi or nginx)
3. **Input Validation**: Already implemented with Pydantic; consider additional sanitization
4. **CORS**: Configure `CORS_ORIGINS` appropriately for your domain
5. **Authentication**: Add API key auth or OAuth for production use

### Performance

1. **Caching**: Cache frequent prompts using Redis/Memcached
2. **Task Queue**: Use Celery/RQ for async diagram generation
3. **Resource Limits**: Set timeouts and memory limits for Graphviz rendering
4. **Connection Pooling**: Use connection pools for database (if adding persistence)

### Monitoring

1. **Logging**: Configure structured logging (JSON format)
2. **Metrics**: Add Prometheus metrics for monitoring
3. **Tracing**: Implement distributed tracing (OpenTelemetry)
4. **Error Tracking**: Use Sentry or similar for error reporting

### Scalability

1. **Horizontal Scaling**: Run multiple instances behind a load balancer
2. **Database**: Add PostgreSQL/MongoDB for storing generated diagrams
3. **CDN**: Serve static frontend assets via CDN
4. **API Gateway**: Use Kong/Traefik for advanced routing and auth

## üõ†Ô∏è Development

### Code Style

```bash
# Format code
black app/ tests/

# Lint
flake8 app/ tests/

# Type checking
mypy app/
```

### Environment Variables Reference

| Variable | Description | Default |
|----------|-------------|---------|
| `LLM_PROVIDER` | LLM provider: `openai` or `nvidia` | `openai` |
| `OPENAI_API_KEY` | OpenAI API key | None |
| `OPENAI_MODEL` | OpenAI model to use | `gpt-4` |
| `OPENAI_BASE_URL` | OpenAI API base URL | `https://api.openai.com/v1` |
| `NVIDIA_API_KEY` | NVIDIA NIM API key | None |
| `NVIDIA_MODEL` | NVIDIA NIM model name | `qwen3-next-80b-a3b-instruct` |
| `NVIDIA_BASE_URL` | NVIDIA NIM API base URL | `https://integrate.api.nvidia.com/v1` |
| `HOST` | Server host | `0.0.0.0` |
| `PORT` | Server port | `8000` |
| `MAX_PROMPT_LENGTH` | Max characters in prompt | `2000` |
| `MAX_DOT_LENGTH` | Max characters in DOT code | `50000` |
| `MAX_TOKENS` | Max LLM response tokens | `1024` |
| `CORS_ORIGINS` | Allowed CORS origins (comma-separated) | `http://localhost:8000,...` |
| `LOG_LEVEL` | Logging level | `INFO` |

## üìù Example Prompts

Try these prompts to get started:

1. **Flowcharts**:
   - "Draw a flowchart for user authentication with login, validation, and error handling"
   - "Create a process flow for order fulfillment with inventory check and payment"

2. **Network Diagrams**:
   - "Show a network topology with router, firewall, web server, and database"
   - "Design a microservices architecture with API gateway, services, and database"

3. **Class Diagrams**:
   - "Create a class diagram for a blog system with User, Post, and Comment classes"
   - "Design an e-commerce class structure with Product, Order, and Customer"

4. **State Machines**:
   - "Draw a state machine for a traffic light system"
   - "Show order states from pending to delivered with transitions"

5. **Organizational Charts**:
   - "Create an org chart for a tech company with CEO, CTO, and engineering teams"
   - "Design a project team structure with PM, developers, and designers"

## üêõ Troubleshooting

### Graphviz Not Found

**Error**: `ExecutableNotFound: failed to execute 'dot'`

**Solution**: Install Graphviz system package (see Prerequisites section)

### LLM API Errors

**Error**: `Failed to generate DOT code`

**Solution**: 
- Check your API key is valid (OPENAI_API_KEY or NVIDIA_API_KEY)
- Ensure you have API credits/access
- Check service status (OpenAI or NVIDIA)
- Verify LLM_PROVIDER is set correctly (`openai` or `nvidia`)
- Check model name is correct for your provider

### Port Already in Use

**Error**: `Address already in use`

**Solution**: Change the PORT environment variable or kill the process using port 8000

### CORS Errors

**Error**: `Access-Control-Allow-Origin` errors in browser

**Solution**: Add your frontend domain to `CORS_ORIGINS` environment variable

## üìÑ License

This project is provided as-is for educational and development purposes.

## ü§ù Contributing

Contributions welcome! Areas for improvement:

- [ ] Add authentication/authorization
- [ ] Implement caching layer
- [ ] Add diagram export to PDF
- [ ] Support for other LLM providers (Anthropic, Azure OpenAI)
- [ ] Diagram editing capabilities
- [ ] Template library
- [ ] Batch diagram generation
- [ ] Webhook support for async generation

## üìß Support

For issues and questions, please check:
1. This README
2. API documentation at `/docs`
3. Test files for usage examples

## üôè Acknowledgments

- [FastAPI](https://fastapi.tiangolo.com/) - Modern web framework
- [Graphviz](https://graphviz.org/) - Graph visualization software
- [OpenAI](https://openai.com/) - LLM provider
- [Python Graphviz](https://graphviz.readthedocs.io/) - Python wrapper

---

Built with ‚ù§Ô∏è using FastAPI and Graphviz

